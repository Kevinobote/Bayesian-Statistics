{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 5: Bayesian Inference in Regression Models\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply Bayesian methods to linear and generalized linear models\n",
    "- Understand Bayesian logistic and Poisson regression\n",
    "- Implement model checking and validation\n",
    "- Handle uncertainty in regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayesian Linear Regression\n",
    "\n",
    "### Model:\n",
    "$$y_i = \\alpha + \\beta x_i + \\epsilon_i, \\quad \\epsilon_i \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "### Priors:\n",
    "- $\\alpha \\sim N(0, 10^2)$\n",
    "- $\\beta \\sim N(0, 10^2)$  \n",
    "- $\\sigma \\sim \\text{HalfNormal}(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "n = 100\n",
    "x = np.random.uniform(0, 10, n)\n",
    "true_alpha, true_beta, true_sigma = 2.0, 1.5, 0.8\n",
    "y = true_alpha + true_beta * x + np.random.normal(0, true_sigma, n)\n",
    "\n",
    "# Bayesian Linear Regression\n",
    "with pm.Model() as linear_model:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', 0, 10)\n",
    "    beta = pm.Normal('beta', 0, 10)\n",
    "    sigma = pm.HalfNormal('sigma', 1)\n",
    "    \n",
    "    # Linear model\n",
    "    mu = alpha + beta * x\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)\n",
    "    \n",
    "    # Sample\n",
    "    trace = pm.sample(2000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Results\n",
    "print(\"Bayesian Linear Regression Results:\")\n",
    "print(f\"True parameters: α={true_alpha}, β={true_beta}, σ={true_sigma}\")\n",
    "print(\"\\nPosterior Summary:\")\n",
    "print(az.summary(trace, var_names=['alpha', 'beta', 'sigma']))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Data and posterior predictions\n",
    "axes[0,0].scatter(x, y, alpha=0.6, label='Data')\n",
    "\n",
    "# Posterior predictive samples\n",
    "alpha_samples = trace.posterior['alpha'].values.flatten()\n",
    "beta_samples = trace.posterior['beta'].values.flatten()\n",
    "\n",
    "x_pred = np.linspace(0, 10, 100)\n",
    "for i in range(0, len(alpha_samples), 100):\n",
    "    y_pred = alpha_samples[i] + beta_samples[i] * x_pred\n",
    "    axes[0,0].plot(x_pred, y_pred, 'r-', alpha=0.1)\n",
    "\n",
    "# True line\n",
    "y_true = true_alpha + true_beta * x_pred\n",
    "axes[0,0].plot(x_pred, y_true, 'g--', linewidth=2, label='True relationship')\n",
    "\n",
    "axes[0,0].set_xlabel('x')\n",
    "axes[0,0].set_ylabel('y')\n",
    "axes[0,0].set_title('Bayesian Linear Regression')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Posterior distributions\n",
    "az.plot_posterior(trace, var_names=['alpha', 'beta'], ax=axes[0,1])\n",
    "axes[0,1].set_title('Posterior Distributions')\n",
    "\n",
    "# Trace plots\n",
    "az.plot_trace(trace, var_names=['alpha', 'beta'], axes=axes[1,:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayesian Logistic Regression\n",
    "\n",
    "### Model:\n",
    "$$\\text{logit}(p_i) = \\alpha + \\beta x_i$$\n",
    "$$y_i \\sim \\text{Bernoulli}(p_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary classification data\n",
    "from sklearn.datasets import make_classification\n",
    "X, y_binary = make_classification(n_samples=200, n_features=1, n_redundant=0, \n",
    "                                 n_informative=1, n_clusters_per_class=1, random_state=42)\n",
    "x_binary = X.flatten()\n",
    "\n",
    "# Bayesian Logistic Regression\n",
    "with pm.Model() as logistic_model:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', 0, 2.5)\n",
    "    beta = pm.Normal('beta', 0, 2.5)\n",
    "    \n",
    "    # Logistic model\n",
    "    logit_p = alpha + beta * x_binary\n",
    "    p = pm.Deterministic('p', pm.math.sigmoid(logit_p))\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Bernoulli('y_obs', p=p, observed=y_binary)\n",
    "    \n",
    "    # Sample\n",
    "    trace_logistic = pm.sample(2000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"Bayesian Logistic Regression Results:\")\n",
    "print(az.summary(trace_logistic, var_names=['alpha', 'beta']))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Data and predictions\n",
    "axes[0].scatter(x_binary[y_binary==0], y_binary[y_binary==0], alpha=0.6, label='Class 0')\n",
    "axes[0].scatter(x_binary[y_binary==1], y_binary[y_binary==1], alpha=0.6, label='Class 1')\n",
    "\n",
    "# Posterior predictive\n",
    "x_pred = np.linspace(x_binary.min(), x_binary.max(), 100)\n",
    "alpha_samples = trace_logistic.posterior['alpha'].values.flatten()\n",
    "beta_samples = trace_logistic.posterior['beta'].values.flatten()\n",
    "\n",
    "for i in range(0, len(alpha_samples), 200):\n",
    "    logit_pred = alpha_samples[i] + beta_samples[i] * x_pred\n",
    "    p_pred = 1 / (1 + np.exp(-logit_pred))\n",
    "    axes[0].plot(x_pred, p_pred, 'r-', alpha=0.1)\n",
    "\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('P(y=1)')\n",
    "axes[0].set_title('Bayesian Logistic Regression')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Posterior distributions\n",
    "az.plot_posterior(trace_logistic, var_names=['alpha', 'beta'], ax=axes[1])\n",
    "axes[1].set_title('Posterior Distributions')\n",
    "\n",
    "# ROC-like analysis\n",
    "p_samples = trace_logistic.posterior['p'].values.reshape(-1, len(x_binary))\n",
    "p_mean = p_samples.mean(axis=0)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_binary, p_mean)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[2].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "axes[2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].set_title('ROC Curve')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesian Poisson Regression\n",
    "\n",
    "### Model:\n",
    "$$\\log(\\lambda_i) = \\alpha + \\beta x_i$$\n",
    "$$y_i \\sim \\text{Poisson}(\\lambda_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate count data\n",
    "n = 100\n",
    "x_count = np.random.uniform(0, 5, n)\n",
    "true_alpha_count, true_beta_count = 0.5, 0.8\n",
    "lambda_true = np.exp(true_alpha_count + true_beta_count * x_count)\n",
    "y_count = np.random.poisson(lambda_true)\n",
    "\n",
    "# Bayesian Poisson Regression\n",
    "with pm.Model() as poisson_model:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', 0, 2)\n",
    "    beta = pm.Normal('beta', 0, 2)\n",
    "    \n",
    "    # Poisson model\n",
    "    log_lambda = alpha + beta * x_count\n",
    "    lambda_param = pm.Deterministic('lambda', pm.math.exp(log_lambda))\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Poisson('y_obs', mu=lambda_param, observed=y_count)\n",
    "    \n",
    "    # Sample\n",
    "    trace_poisson = pm.sample(2000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"Bayesian Poisson Regression Results:\")\n",
    "print(f\"True parameters: α={true_alpha_count}, β={true_beta_count}\")\n",
    "print(\"\\nPosterior Summary:\")\n",
    "print(az.summary(trace_poisson, var_names=['alpha', 'beta']))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Data and predictions\n",
    "axes[0].scatter(x_count, y_count, alpha=0.6, label='Data')\n",
    "\n",
    "# Posterior predictive\n",
    "x_pred = np.linspace(0, 5, 100)\n",
    "alpha_samples = trace_poisson.posterior['alpha'].values.flatten()\n",
    "beta_samples = trace_poisson.posterior['beta'].values.flatten()\n",
    "\n",
    "for i in range(0, len(alpha_samples), 200):\n",
    "    lambda_pred = np.exp(alpha_samples[i] + beta_samples[i] * x_pred)\n",
    "    axes[0].plot(x_pred, lambda_pred, 'r-', alpha=0.1)\n",
    "\n",
    "# True relationship\n",
    "lambda_true_pred = np.exp(true_alpha_count + true_beta_count * x_pred)\n",
    "axes[0].plot(x_pred, lambda_true_pred, 'g--', linewidth=2, label='True λ(x)')\n",
    "\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Bayesian Poisson Regression')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Posterior distributions\n",
    "az.plot_posterior(trace_poisson, var_names=['alpha', 'beta'], ax=axes[1])\n",
    "axes[1].set_title('Posterior Distributions')\n",
    "\n",
    "# Residual analysis\n",
    "lambda_samples = trace_poisson.posterior['lambda'].values.reshape(-1, len(x_count))\n",
    "lambda_mean = lambda_samples.mean(axis=0)\n",
    "residuals = y_count - lambda_mean\n",
    "\n",
    "axes[2].scatter(lambda_mean, residuals, alpha=0.6)\n",
    "axes[2].axhline(0, color='red', linestyle='--')\n",
    "axes[2].set_xlabel('Fitted Values')\n",
    "axes[2].set_ylabel('Residuals')\n",
    "axes[2].set_title('Residual Plot')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Advantages of Bayesian Regression:\n",
    "- **Full uncertainty quantification** for all parameters\n",
    "- **Natural regularization** through priors\n",
    "- **Flexible model specification** and extensions\n",
    "- **Principled model comparison** via information criteria\n",
    "\n",
    "### Model Checking:\n",
    "- **Posterior predictive checks** assess model adequacy\n",
    "- **Residual analysis** identifies model violations\n",
    "- **Cross-validation** evaluates predictive performance\n",
    "\n",
    "## Next: Topic 6 - Hierarchical Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}