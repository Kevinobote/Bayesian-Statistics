{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 6: Bayesian Hierarchical Models and Missing Data\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand hierarchical model structure and benefits\n",
    "- Implement partial pooling vs complete pooling\n",
    "- Handle missing data in Bayesian framework\n",
    "- Apply model checking for hierarchical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hierarchical Model Example: School Performance\n",
    "\n",
    "### Model Structure:\n",
    "- **Level 1**: Student scores within schools\n",
    "- **Level 2**: School-specific parameters\n",
    "- **Level 3**: Population-level hyperparameters\n",
    "\n",
    "$$y_{ij} \\sim N(\\mu_j, \\sigma^2)$$\n",
    "$$\\mu_j \\sim N(\\alpha, \\tau^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hierarchical data\n",
    "n_schools = 8\n",
    "n_students_per_school = [20, 15, 25, 18, 22, 16, 19, 21]\n",
    "true_alpha = 75  # Overall mean\n",
    "true_tau = 8     # Between-school SD\n",
    "true_sigma = 12  # Within-school SD\n",
    "\n",
    "# Generate school means\n",
    "true_school_means = np.random.normal(true_alpha, true_tau, n_schools)\n",
    "\n",
    "# Generate student scores\n",
    "schools = []\n",
    "scores = []\n",
    "school_names = [f'School_{i+1}' for i in range(n_schools)]\n",
    "\n",
    "for i, (n_students, school_mean) in enumerate(zip(n_students_per_school, true_school_means)):\n",
    "    school_scores = np.random.normal(school_mean, true_sigma, n_students)\n",
    "    schools.extend([i] * n_students)\n",
    "    scores.extend(school_scores)\n",
    "\n",
    "schools = np.array(schools)\n",
    "scores = np.array(scores)\n",
    "\n",
    "print(f\"Generated data: {len(scores)} students across {n_schools} schools\")\n",
    "print(f\"True parameters: α={true_alpha}, τ={true_tau}, σ={true_sigma}\")\n",
    "\n",
    "# Hierarchical Model\n",
    "with pm.Model() as hierarchical_model:\n",
    "    # Hyperpriors\n",
    "    alpha = pm.Normal('alpha', 70, 10)  # Overall mean\n",
    "    tau = pm.HalfNormal('tau', 10)      # Between-school SD\n",
    "    sigma = pm.HalfNormal('sigma', 10)  # Within-school SD\n",
    "    \n",
    "    # School-specific means\n",
    "    mu_school = pm.Normal('mu_school', alpha, tau, shape=n_schools)\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal('y_obs', mu_school[schools], sigma, observed=scores)\n",
    "    \n",
    "    # Sample\n",
    "    trace_hier = pm.sample(2000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"\\nHierarchical Model Results:\")\n",
    "print(az.summary(trace_hier, var_names=['alpha', 'tau', 'sigma']))\n",
    "\n",
    "# Compare with pooled and unpooled models\n",
    "# Complete pooling (ignore schools)\n",
    "with pm.Model() as pooled_model:\n",
    "    mu_pooled = pm.Normal('mu_pooled', 70, 10)\n",
    "    sigma_pooled = pm.HalfNormal('sigma_pooled', 10)\n",
    "    y_obs = pm.Normal('y_obs', mu_pooled, sigma_pooled, observed=scores)\n",
    "    trace_pooled = pm.sample(1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# No pooling (separate analysis for each school)\n",
    "unpooled_means = []\n",
    "for i in range(n_schools):\n",
    "    school_scores = scores[schools == i]\n",
    "    unpooled_means.append(np.mean(school_scores))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Raw data\n",
    "school_data = [scores[schools == i] for i in range(n_schools)]\n",
    "axes[0,0].boxplot(school_data, labels=school_names)\n",
    "axes[0,0].set_ylabel('Test Scores')\n",
    "axes[0,0].set_title('Raw Data by School')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Compare estimates\n",
    "hier_means = trace_hier.posterior['mu_school'].mean(dim=['chain', 'draw']).values\n",
    "pooled_mean = trace_pooled.posterior['mu_pooled'].mean().values\n",
    "\n",
    "x_pos = np.arange(n_schools)\n",
    "width = 0.25\n",
    "\n",
    "axes[0,1].bar(x_pos - width, true_school_means, width, label='True', alpha=0.7)\n",
    "axes[0,1].bar(x_pos, unpooled_means, width, label='No Pooling', alpha=0.7)\n",
    "axes[0,1].bar(x_pos + width, hier_means, width, label='Partial Pooling', alpha=0.7)\n",
    "axes[0,1].axhline(pooled_mean, color='red', linestyle='--', label='Complete Pooling')\n",
    "\n",
    "axes[0,1].set_xlabel('School')\n",
    "axes[0,1].set_ylabel('Mean Score')\n",
    "axes[0,1].set_title('Comparison of Estimates')\n",
    "axes[0,1].set_xticks(x_pos)\n",
    "axes[0,1].set_xticklabels(school_names, rotation=45)\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Shrinkage plot\n",
    "axes[1,0].scatter(unpooled_means, hier_means, s=60, alpha=0.7)\n",
    "axes[1,0].plot([60, 90], [60, 90], 'k--', alpha=0.5)\n",
    "axes[1,0].axhline(trace_hier.posterior['alpha'].mean().values, color='red', \n",
    "                 linestyle=':', label='Population mean')\n",
    "axes[1,0].set_xlabel('No Pooling Estimate')\n",
    "axes[1,0].set_ylabel('Partial Pooling Estimate')\n",
    "axes[1,0].set_title('Shrinkage Effect')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Posterior distributions\n",
    "az.plot_forest(trace_hier, var_names=['mu_school'], ax=axes[1,1])\n",
    "axes[1,1].set_title('School-Specific Means (95% CI)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate shrinkage\n",
    "shrinkage = 1 - (hier_means - trace_hier.posterior['alpha'].mean().values) / \\\n",
    "                (np.array(unpooled_means) - trace_hier.posterior['alpha'].mean().values)\n",
    "\n",
    "print(\"\\nShrinkage Analysis:\")\n",
    "for i, (name, shr) in enumerate(zip(school_names, shrinkage)):\n",
    "    n_students = n_students_per_school[i]\n",
    "    print(f\"{name}: {shr:.3f} (n={n_students})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Data Handling\n",
    "\n",
    "Bayesian methods naturally handle missing data through imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with missing values\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "x_complete = np.random.normal(0, 1, n)\n",
    "y_complete = 2 + 3 * x_complete + np.random.normal(0, 1, n)\n",
    "\n",
    "# Introduce missing values (MCAR - Missing Completely at Random)\n",
    "missing_prob = 0.3\n",
    "x_missing_mask = np.random.random(n) < missing_prob\n",
    "y_missing_mask = np.random.random(n) < missing_prob\n",
    "\n",
    "x_observed = x_complete.copy()\n",
    "y_observed = y_complete.copy()\n",
    "x_observed[x_missing_mask] = np.nan\n",
    "y_observed[y_missing_mask] = np.nan\n",
    "\n",
    "# Keep only cases with at least one observed value\n",
    "complete_missing = x_missing_mask & y_missing_mask\n",
    "keep_mask = ~complete_missing\n",
    "\n",
    "x_obs = x_observed[keep_mask]\n",
    "y_obs = y_observed[keep_mask]\n",
    "n_keep = np.sum(keep_mask)\n",
    "\n",
    "print(f\"Original data: {n} observations\")\n",
    "print(f\"After removing completely missing: {n_keep} observations\")\n",
    "print(f\"Missing x values: {np.sum(np.isnan(x_obs))}\")\n",
    "print(f\"Missing y values: {np.sum(np.isnan(y_obs))}\")\n",
    "\n",
    "# Bayesian model with missing data\n",
    "with pm.Model() as missing_data_model:\n",
    "    # Priors for regression parameters\n",
    "    alpha = pm.Normal('alpha', 0, 10)\n",
    "    beta = pm.Normal('beta', 0, 10)\n",
    "    sigma = pm.HalfNormal('sigma', 2)\n",
    "    \n",
    "    # Priors for missing data parameters\n",
    "    mu_x = pm.Normal('mu_x', 0, 2)\n",
    "    sigma_x = pm.HalfNormal('sigma_x', 2)\n",
    "    \n",
    "    # Impute missing x values\n",
    "    x_imputed = pm.Normal('x_imputed', mu_x, sigma_x, \n",
    "                         shape=n_keep, observed=x_obs)\n",
    "    \n",
    "    # Regression model\n",
    "    mu_y = alpha + beta * x_imputed\n",
    "    \n",
    "    # Impute missing y values\n",
    "    y_imputed = pm.Normal('y_imputed', mu_y, sigma, \n",
    "                         shape=n_keep, observed=y_obs)\n",
    "    \n",
    "    # Sample\n",
    "    trace_missing = pm.sample(2000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"\\nMissing Data Model Results:\")\n",
    "print(az.summary(trace_missing, var_names=['alpha', 'beta', 'sigma', 'mu_x', 'sigma_x']))\n",
    "\n",
    "# Compare with complete case analysis\n",
    "complete_cases = ~(np.isnan(x_obs) | np.isnan(y_obs))\n",
    "x_complete_cases = x_obs[complete_cases]\n",
    "y_complete_cases = y_obs[complete_cases]\n",
    "\n",
    "print(f\"\\nComplete case analysis: {np.sum(complete_cases)} observations\")\n",
    "print(f\"True parameters: α=2, β=3, σ=1\")\n",
    "\n",
    "# Simple linear regression on complete cases\n",
    "from scipy import stats as scipy_stats\n",
    "slope, intercept, r_value, p_value, std_err = scipy_stats.linregress(x_complete_cases, y_complete_cases)\n",
    "print(f\"Complete case estimates: α={intercept:.3f}, β={slope:.3f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Missing data pattern\n",
    "missing_pattern = pd.DataFrame({\n",
    "    'x': ~np.isnan(x_obs),\n",
    "    'y': ~np.isnan(y_obs)\n",
    "})\n",
    "\n",
    "pattern_counts = missing_pattern.value_counts().sort_index()\n",
    "pattern_labels = [f'x:{x}, y:{y}' for (x, y) in pattern_counts.index]\n",
    "\n",
    "axes[0,0].bar(range(len(pattern_counts)), pattern_counts.values)\n",
    "axes[0,0].set_xticks(range(len(pattern_counts)))\n",
    "axes[0,0].set_xticklabels(pattern_labels, rotation=45)\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].set_title('Missing Data Patterns')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Observed vs imputed\n",
    "x_imputed_samples = trace_missing.posterior['x_imputed'].values.reshape(-1, n_keep)\n",
    "y_imputed_samples = trace_missing.posterior['y_imputed'].values.reshape(-1, n_keep)\n",
    "\n",
    "x_imputed_mean = np.nanmean(x_imputed_samples, axis=0)\n",
    "y_imputed_mean = np.nanmean(y_imputed_samples, axis=0)\n",
    "\n",
    "# Plot observed data\n",
    "obs_mask = ~np.isnan(x_obs) & ~np.isnan(y_obs)\n",
    "axes[0,1].scatter(x_obs[obs_mask], y_obs[obs_mask], alpha=0.7, label='Observed', s=30)\n",
    "\n",
    "# Plot imputed data\n",
    "imp_mask = np.isnan(x_obs) | np.isnan(y_obs)\n",
    "if np.any(imp_mask):\n",
    "    axes[0,1].scatter(x_imputed_mean[imp_mask], y_imputed_mean[imp_mask], \n",
    "                     alpha=0.7, label='Imputed', s=30, marker='s')\n",
    "\n",
    "# Regression lines\n",
    "x_plot = np.linspace(-3, 3, 100)\n",
    "alpha_mean = trace_missing.posterior['alpha'].mean().values\n",
    "beta_mean = trace_missing.posterior['beta'].mean().values\n",
    "\n",
    "axes[0,1].plot(x_plot, alpha_mean + beta_mean * x_plot, 'r-', \n",
    "              label='Bayesian (with imputation)', linewidth=2)\n",
    "axes[0,1].plot(x_plot, intercept + slope * x_plot, 'g--', \n",
    "              label='Complete case analysis', linewidth=2)\n",
    "axes[0,1].plot(x_plot, 2 + 3 * x_plot, 'k:', \n",
    "              label='True relationship', linewidth=2)\n",
    "\n",
    "axes[0,1].set_xlabel('x')\n",
    "axes[0,1].set_ylabel('y')\n",
    "axes[0,1].set_title('Observed vs Imputed Data')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Posterior distributions\n",
    "az.plot_posterior(trace_missing, var_names=['alpha', 'beta'], ax=axes[1,0])\n",
    "axes[1,0].set_title('Posterior Distributions')\n",
    "\n",
    "# Imputation uncertainty\n",
    "if np.any(np.isnan(x_obs)):\n",
    "    missing_x_idx = np.where(np.isnan(x_obs))[0]\n",
    "    if len(missing_x_idx) > 0:\n",
    "        idx = missing_x_idx[0]  # Show first missing x\n",
    "        x_samples = x_imputed_samples[:, idx]\n",
    "        axes[1,1].hist(x_samples, bins=30, alpha=0.7, density=True)\n",
    "        axes[1,1].axvline(x_complete[keep_mask][idx], color='red', linestyle='--', \n",
    "                         label='True value')\n",
    "        axes[1,1].set_xlabel('Imputed x value')\n",
    "        axes[1,1].set_ylabel('Density')\n",
    "        axes[1,1].set_title(f'Imputation Uncertainty (obs {idx})')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Hierarchical Models:\n",
    "- **Partial pooling** balances individual and group information\n",
    "- **Shrinkage** toward group mean depends on sample size\n",
    "- **Borrowing strength** improves estimates for small groups\n",
    "- **Natural regularization** prevents overfitting\n",
    "\n",
    "### Missing Data:\n",
    "- **Bayesian imputation** naturally quantifies uncertainty\n",
    "- **Joint modeling** of missing data mechanism and outcome\n",
    "- **Multiple imputation** through posterior sampling\n",
    "- **Assumptions matter**: MCAR, MAR, MNAR\n",
    "\n",
    "## Next: Topic 7 - MCMC Methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}