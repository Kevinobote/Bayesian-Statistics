{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 4: Bayesian Hypothesis Testing and Model Averaging\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand Bayesian hypothesis testing framework\n",
    "- Master Bayes factors for model comparison\n",
    "- Apply Bayesian model averaging\n",
    "- Perform sensitivity analysis in model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy.special import beta as beta_func\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayes Factors\n",
    "\n",
    "### Definition:\n",
    "$$BF_{12} = \\frac{P(D|M_1)}{P(D|M_2)} = \\frac{\\text{Evidence for } M_1}{\\text{Evidence for } M_2}$$\n",
    "\n",
    "### Interpretation (Kass & Raftery, 1995):\n",
    "- BF > 10: Strong evidence for M₁\n",
    "- BF > 3: Moderate evidence for M₁  \n",
    "- BF ≈ 1: No evidence either way\n",
    "- BF < 1/3: Moderate evidence for M₂\n",
    "- BF < 1/10: Strong evidence for M₂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes Factor example: Is a coin fair?\n",
    "# H₀: p = 0.5 (fair coin)\n",
    "# H₁: p ≠ 0.5 (unfair coin)\n",
    "\n",
    "def coin_bayes_factor(heads, tails, alpha=1, beta=1):\n",
    "    \"\"\"\n",
    "    Calculate Bayes factor for fair vs unfair coin\n",
    "    H0: p = 0.5 (point hypothesis)\n",
    "    H1: p ~ Beta(alpha, beta) (composite hypothesis)\n",
    "    \"\"\"\n",
    "    n = heads + tails\n",
    "    \n",
    "    # Likelihood under H0 (p = 0.5)\n",
    "    likelihood_h0 = stats.binom.pmf(heads, n, 0.5)\n",
    "    \n",
    "    # Marginal likelihood under H1 (Beta-Binomial)\n",
    "    # P(D|H1) = Beta(heads + alpha, tails + beta) / Beta(alpha, beta) * C(n, heads)\n",
    "    marginal_h1 = (beta_func(heads + alpha, tails + beta) / \n",
    "                   beta_func(alpha, beta) * \n",
    "                   stats.binom.pmf(heads, n, 0.5) / (0.5**n))\n",
    "    \n",
    "    # Simpler formula for Beta-Binomial\n",
    "    from scipy.special import comb\n",
    "    marginal_h1 = (comb(n, heads) * \n",
    "                   beta_func(heads + alpha, tails + beta) / \n",
    "                   beta_func(alpha, beta))\n",
    "    \n",
    "    bayes_factor = likelihood_h0 / marginal_h1\n",
    "    \n",
    "    return bayes_factor, likelihood_h0, marginal_h1\n",
    "\n",
    "# Test different scenarios\n",
    "scenarios = [\n",
    "    (5, 5, \"Balanced\"),\n",
    "    (7, 3, \"Slightly biased\"),\n",
    "    (8, 2, \"Moderately biased\"),\n",
    "    (9, 1, \"Strongly biased\")\n",
    "]\n",
    "\n",
    "print(\"Bayes Factor Analysis: Fair vs Unfair Coin\")\n",
    "print(\"H₀: p = 0.5, H₁: p ~ Beta(1,1)\")\n",
    "print(\"\\nScenario\\t\\tHeads/Tails\\tBF₀₁\\tEvidence\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "bfs = []\n",
    "for heads, tails, description in scenarios:\n",
    "    bf, _, _ = coin_bayes_factor(heads, tails)\n",
    "    bfs.append(bf)\n",
    "    \n",
    "    if bf > 3:\n",
    "        evidence = \"For H₀ (fair)\"\n",
    "    elif bf > 1:\n",
    "        evidence = \"Weak for H₀\"\n",
    "    elif bf > 1/3:\n",
    "        evidence = \"Inconclusive\"\n",
    "    else:\n",
    "        evidence = \"Against H₀ (unfair)\"\n",
    "    \n",
    "    print(f\"{description:<15}\\t{heads}/{tails}\\t\\t{bf:.2f}\\t{evidence}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Bayes factors\n",
    "plt.subplot(2, 2, 1)\n",
    "scenarios_names = [s[2] for s in scenarios]\n",
    "colors = ['green' if bf > 3 else 'orange' if bf > 1 else 'red' for bf in bfs]\n",
    "bars = plt.bar(scenarios_names, bfs, color=colors, alpha=0.7)\n",
    "plt.axhline(1, color='black', linestyle='--', label='No evidence')\n",
    "plt.axhline(3, color='green', linestyle=':', label='Moderate evidence')\n",
    "plt.axhline(1/3, color='red', linestyle=':', label='Evidence against')\n",
    "plt.ylabel('Bayes Factor (BF₀₁)')\n",
    "plt.title('Bayes Factors for Fair Coin')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Posterior probabilities under H1\n",
    "plt.subplot(2, 2, 2)\n",
    "x = np.linspace(0, 1, 1000)\n",
    "for i, (heads, tails, description) in enumerate(scenarios):\n",
    "    posterior = stats.beta(1 + heads, 1 + tails)\n",
    "    plt.plot(x, posterior.pdf(x), label=f'{description} ({heads}H, {tails}T)', \n",
    "             linewidth=2, alpha=0.8)\n",
    "\n",
    "plt.axvline(0.5, color='black', linestyle='--', label='H₀: p = 0.5')\n",
    "plt.xlabel('p (probability of heads)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Posterior Distributions under H₁')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Sequential Bayes factors\n",
    "plt.subplot(2, 2, 3)\n",
    "# Simulate sequential coin flips\n",
    "np.random.seed(42)\n",
    "true_p = 0.7\n",
    "n_flips = 30\n",
    "flips = np.random.binomial(1, true_p, n_flips)\n",
    "\n",
    "sequential_bfs = []\n",
    "for i in range(1, n_flips + 1):\n",
    "    heads = np.sum(flips[:i])\n",
    "    tails = i - heads\n",
    "    bf, _, _ = coin_bayes_factor(heads, tails)\n",
    "    sequential_bfs.append(bf)\n",
    "\n",
    "plt.plot(range(1, n_flips + 1), sequential_bfs, 'b-', linewidth=2)\n",
    "plt.axhline(1, color='black', linestyle='--', alpha=0.7)\n",
    "plt.axhline(3, color='green', linestyle=':', alpha=0.7)\n",
    "plt.axhline(1/3, color='red', linestyle=':', alpha=0.7)\n",
    "plt.xlabel('Number of Flips')\n",
    "plt.ylabel('Bayes Factor (BF₀₁)')\n",
    "plt.title(f'Sequential Evidence (true p = {true_p})')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Model probabilities\n",
    "plt.subplot(2, 2, 4)\n",
    "prior_h0 = 0.5  # Prior probability of H0\n",
    "model_probs_h0 = []\n",
    "model_probs_h1 = []\n",
    "\n",
    "for bf in sequential_bfs:\n",
    "    # Posterior model probabilities\n",
    "    posterior_odds = bf * (prior_h0 / (1 - prior_h0))\n",
    "    prob_h0 = posterior_odds / (1 + posterior_odds)\n",
    "    prob_h1 = 1 - prob_h0\n",
    "    \n",
    "    model_probs_h0.append(prob_h0)\n",
    "    model_probs_h1.append(prob_h1)\n",
    "\n",
    "plt.plot(range(1, n_flips + 1), model_probs_h0, 'g-', linewidth=2, label='P(H₀|data)')\n",
    "plt.plot(range(1, n_flips + 1), model_probs_h1, 'r-', linewidth=2, label='P(H₁|data)')\n",
    "plt.axhline(0.5, color='black', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Number of Flips')\n",
    "plt.ylabel('Model Probability')\n",
    "plt.title('Sequential Model Probabilities')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Comparison with PyMC\n",
    "\n",
    "Compare different regression models using WAIC and LOO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n = 50\n",
    "x = np.linspace(0, 1, n)\n",
    "true_y = 2 + 3*x + 0.5*x**2 + np.random.normal(0, 0.3, n)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, true_y, alpha=0.7, label='Data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Synthetic Dataset')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Model 1: Linear\n",
    "with pm.Model() as model_linear:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', 0, 10)\n",
    "    beta = pm.Normal('beta', 0, 10)\n",
    "    sigma = pm.HalfNormal('sigma', 1)\n",
    "    \n",
    "    # Linear model\n",
    "    mu = alpha + beta * x\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=true_y)\n",
    "    \n",
    "    # Sample\n",
    "    trace_linear = pm.sample(1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Model 2: Quadratic\n",
    "with pm.Model() as model_quad:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', 0, 10)\n",
    "    beta1 = pm.Normal('beta1', 0, 10)\n",
    "    beta2 = pm.Normal('beta2', 0, 10)\n",
    "    sigma = pm.HalfNormal('sigma', 1)\n",
    "    \n",
    "    # Quadratic model\n",
    "    mu = alpha + beta1 * x + beta2 * x**2\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=true_y)\n",
    "    \n",
    "    # Sample\n",
    "    trace_quad = pm.sample(1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Model 3: Cubic\n",
    "with pm.Model() as model_cubic:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', 0, 10)\n",
    "    beta1 = pm.Normal('beta1', 0, 10)\n",
    "    beta2 = pm.Normal('beta2', 0, 10)\n",
    "    beta3 = pm.Normal('beta3', 0, 10)\n",
    "    sigma = pm.HalfNormal('sigma', 1)\n",
    "    \n",
    "    # Cubic model\n",
    "    mu = alpha + beta1 * x + beta2 * x**2 + beta3 * x**3\n",
    "    \n",
    "    # Likelihood\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=true_y)\n",
    "    \n",
    "    # Sample\n",
    "    trace_cubic = pm.sample(1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "# Model comparison\n",
    "models = {\n",
    "    'Linear': trace_linear,\n",
    "    'Quadratic': trace_quad,\n",
    "    'Cubic': trace_cubic\n",
    "}\n",
    "\n",
    "# Calculate WAIC and LOO\n",
    "comparison = az.compare(models, ic='waic')\n",
    "print(\"Model Comparison (WAIC):\")\n",
    "print(comparison)\n",
    "\n",
    "# Plot comparison\n",
    "az.plot_compare(comparison)\n",
    "plt.title('Model Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Posterior predictive checks\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "x_pred = np.linspace(0, 1, 100)\n",
    "model_names = ['Linear', 'Quadratic', 'Cubic']\n",
    "traces = [trace_linear, trace_quad, trace_cubic]\n",
    "\n",
    "for i, (name, trace) in enumerate(zip(model_names, traces)):\n",
    "    axes[i].scatter(x, true_y, alpha=0.7, color='black', label='Data')\n",
    "    \n",
    "    # Posterior predictive samples\n",
    "    if name == 'Linear':\n",
    "        alpha_samples = trace.posterior['alpha'].values.flatten()\n",
    "        beta_samples = trace.posterior['beta'].values.flatten()\n",
    "        \n",
    "        for j in range(0, len(alpha_samples), 50):\n",
    "            y_pred = alpha_samples[j] + beta_samples[j] * x_pred\n",
    "            axes[i].plot(x_pred, y_pred, 'b-', alpha=0.1)\n",
    "    \n",
    "    elif name == 'Quadratic':\n",
    "        alpha_samples = trace.posterior['alpha'].values.flatten()\n",
    "        beta1_samples = trace.posterior['beta1'].values.flatten()\n",
    "        beta2_samples = trace.posterior['beta2'].values.flatten()\n",
    "        \n",
    "        for j in range(0, len(alpha_samples), 50):\n",
    "            y_pred = (alpha_samples[j] + beta1_samples[j] * x_pred + \n",
    "                     beta2_samples[j] * x_pred**2)\n",
    "            axes[i].plot(x_pred, y_pred, 'r-', alpha=0.1)\n",
    "    \n",
    "    else:  # Cubic\n",
    "        alpha_samples = trace.posterior['alpha'].values.flatten()\n",
    "        beta1_samples = trace.posterior['beta1'].values.flatten()\n",
    "        beta2_samples = trace.posterior['beta2'].values.flatten()\n",
    "        beta3_samples = trace.posterior['beta3'].values.flatten()\n",
    "        \n",
    "        for j in range(0, len(alpha_samples), 50):\n",
    "            y_pred = (alpha_samples[j] + beta1_samples[j] * x_pred + \n",
    "                     beta2_samples[j] * x_pred**2 + beta3_samples[j] * x_pred**3)\n",
    "            axes[i].plot(x_pred, y_pred, 'g-', alpha=0.1)\n",
    "    \n",
    "    axes[i].set_title(f'{name} Model')\n",
    "    axes[i].set_xlabel('x')\n",
    "    axes[i].set_ylabel('y')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesian Model Averaging\n",
    "\n",
    "Instead of selecting one \"best\" model, average predictions across models weighted by their posterior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Model Averaging example\n",
    "# Convert WAIC to model weights\n",
    "\n",
    "def waic_to_weights(waic_values):\n",
    "    \"\"\"\n",
    "    Convert WAIC values to model weights\n",
    "    \"\"\"\n",
    "    # Use Akaike weights\n",
    "    min_waic = np.min(waic_values)\n",
    "    delta_waic = waic_values - min_waic\n",
    "    weights = np.exp(-0.5 * delta_waic)\n",
    "    weights = weights / np.sum(weights)\n",
    "    return weights\n",
    "\n",
    "# Get WAIC values\n",
    "waic_values = np.array([comparison.loc[model, 'waic'] for model in ['Linear', 'Quadratic', 'Cubic']])\n",
    "model_weights = waic_to_weights(waic_values)\n",
    "\n",
    "print(\"Model Weights (based on WAIC):\")\n",
    "for i, (name, weight) in enumerate(zip(['Linear', 'Quadratic', 'Cubic'], model_weights)):\n",
    "    print(f\"{name}: {weight:.3f}\")\n",
    "\n",
    "# Bayesian Model Averaging prediction\n",
    "x_new = np.array([0.25, 0.5, 0.75])  # New prediction points\n",
    "\n",
    "print(f\"\\nBayesian Model Averaging Predictions:\")\n",
    "print(f\"x\\tLinear\\tQuadratic\\tCubic\\tBMA\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for x_val in x_new:\n",
    "    # Individual model predictions (using posterior means)\n",
    "    # Linear\n",
    "    alpha_mean = trace_linear.posterior['alpha'].mean().values\n",
    "    beta_mean = trace_linear.posterior['beta'].mean().values\n",
    "    pred_linear = alpha_mean + beta_mean * x_val\n",
    "    \n",
    "    # Quadratic\n",
    "    alpha_mean = trace_quad.posterior['alpha'].mean().values\n",
    "    beta1_mean = trace_quad.posterior['beta1'].mean().values\n",
    "    beta2_mean = trace_quad.posterior['beta2'].mean().values\n",
    "    pred_quad = alpha_mean + beta1_mean * x_val + beta2_mean * x_val**2\n",
    "    \n",
    "    # Cubic\n",
    "    alpha_mean = trace_cubic.posterior['alpha'].mean().values\n",
    "    beta1_mean = trace_cubic.posterior['beta1'].mean().values\n",
    "    beta2_mean = trace_cubic.posterior['beta2'].mean().values\n",
    "    beta3_mean = trace_cubic.posterior['beta3'].mean().values\n",
    "    pred_cubic = (alpha_mean + beta1_mean * x_val + \n",
    "                  beta2_mean * x_val**2 + beta3_mean * x_val**3)\n",
    "    \n",
    "    # BMA prediction\n",
    "    predictions = np.array([pred_linear, pred_quad, pred_cubic])\n",
    "    bma_pred = np.sum(model_weights * predictions)\n",
    "    \n",
    "    print(f\"{x_val:.2f}\\t{pred_linear:.2f}\\t{pred_quad:.2f}\\t\\t{pred_cubic:.2f}\\t{bma_pred:.2f}\")\n",
    "\n",
    "# Visualization of BMA\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Model weights\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(['Linear', 'Quadratic', 'Cubic'], model_weights, \n",
    "        color=['blue', 'red', 'green'], alpha=0.7)\n",
    "plt.ylabel('Model Weight')\n",
    "plt.title('Model Weights (WAIC-based)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# BMA prediction\n",
    "plt.subplot(2, 2, 2)\n",
    "x_pred = np.linspace(0, 1, 100)\n",
    "\n",
    "# Individual model predictions\n",
    "alpha_mean = trace_linear.posterior['alpha'].mean().values\n",
    "beta_mean = trace_linear.posterior['beta'].mean().values\n",
    "pred_linear_full = alpha_mean + beta_mean * x_pred\n",
    "\n",
    "alpha_mean = trace_quad.posterior['alpha'].mean().values\n",
    "beta1_mean = trace_quad.posterior['beta1'].mean().values\n",
    "beta2_mean = trace_quad.posterior['beta2'].mean().values\n",
    "pred_quad_full = alpha_mean + beta1_mean * x_pred + beta2_mean * x_pred**2\n",
    "\n",
    "alpha_mean = trace_cubic.posterior['alpha'].mean().values\n",
    "beta1_mean = trace_cubic.posterior['beta1'].mean().values\n",
    "beta2_mean = trace_cubic.posterior['beta2'].mean().values\n",
    "beta3_mean = trace_cubic.posterior['beta3'].mean().values\n",
    "pred_cubic_full = (alpha_mean + beta1_mean * x_pred + \n",
    "                   beta2_mean * x_pred**2 + beta3_mean * x_pred**3)\n",
    "\n",
    "# BMA prediction\n",
    "bma_pred_full = (model_weights[0] * pred_linear_full + \n",
    "                 model_weights[1] * pred_quad_full + \n",
    "                 model_weights[2] * pred_cubic_full)\n",
    "\n",
    "plt.scatter(x, true_y, alpha=0.7, color='black', label='Data')\n",
    "plt.plot(x_pred, pred_linear_full, 'b--', alpha=0.7, \n",
    "         label=f'Linear (w={model_weights[0]:.2f})')\n",
    "plt.plot(x_pred, pred_quad_full, 'r--', alpha=0.7, \n",
    "         label=f'Quadratic (w={model_weights[1]:.2f})')\n",
    "plt.plot(x_pred, pred_cubic_full, 'g--', alpha=0.7, \n",
    "         label=f'Cubic (w={model_weights[2]:.2f})')\n",
    "plt.plot(x_pred, bma_pred_full, 'k-', linewidth=3, label='BMA')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Bayesian Model Averaging')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Model uncertainty\n",
    "plt.subplot(2, 2, 3)\n",
    "# Calculate prediction variance across models\n",
    "pred_matrix = np.array([pred_linear_full, pred_quad_full, pred_cubic_full])\n",
    "bma_variance = np.sum(model_weights[:, np.newaxis] * \n",
    "                      (pred_matrix - bma_pred_full)**2, axis=0)\n",
    "\n",
    "plt.plot(x_pred, np.sqrt(bma_variance), 'purple', linewidth=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Prediction Standard Deviation')\n",
    "plt.title('Model Uncertainty')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative model weights (as data arrives)\n",
    "plt.subplot(2, 2, 4)\n",
    "# Simulate how model weights change with sample size\n",
    "sample_sizes = range(10, len(x), 5)\n",
    "weight_evolution = {'Linear': [], 'Quadratic': [], 'Cubic': []}\n",
    "\n",
    "for n_sample in sample_sizes:\n",
    "    x_sub = x[:n_sample]\n",
    "    y_sub = true_y[:n_sample]\n",
    "    \n",
    "    # Fit models to subset (simplified - just compute AIC approximation)\n",
    "    # Linear\n",
    "    p_linear = np.polyfit(x_sub, y_sub, 1)\n",
    "    pred_linear_sub = np.polyval(p_linear, x_sub)\n",
    "    mse_linear = np.mean((y_sub - pred_linear_sub)**2)\n",
    "    aic_linear = n_sample * np.log(mse_linear) + 2 * 2  # 2 parameters\n",
    "    \n",
    "    # Quadratic\n",
    "    p_quad = np.polyfit(x_sub, y_sub, 2)\n",
    "    pred_quad_sub = np.polyval(p_quad, x_sub)\n",
    "    mse_quad = np.mean((y_sub - pred_quad_sub)**2)\n",
    "    aic_quad = n_sample * np.log(mse_quad) + 2 * 3  # 3 parameters\n",
    "    \n",
    "    # Cubic\n",
    "    p_cubic = np.polyfit(x_sub, y_sub, 3)\n",
    "    pred_cubic_sub = np.polyval(p_cubic, x_sub)\n",
    "    mse_cubic = np.mean((y_sub - pred_cubic_sub)**2)\n",
    "    aic_cubic = n_sample * np.log(mse_cubic) + 2 * 4  # 4 parameters\n",
    "    \n",
    "    # Convert to weights\n",
    "    aic_values = np.array([aic_linear, aic_quad, aic_cubic])\n",
    "    weights_sub = waic_to_weights(aic_values)\n",
    "    \n",
    "    weight_evolution['Linear'].append(weights_sub[0])\n",
    "    weight_evolution['Quadratic'].append(weights_sub[1])\n",
    "    weight_evolution['Cubic'].append(weights_sub[2])\n",
    "\n",
    "plt.plot(sample_sizes, weight_evolution['Linear'], 'b-', label='Linear')\n",
    "plt.plot(sample_sizes, weight_evolution['Quadratic'], 'r-', label='Quadratic')\n",
    "plt.plot(sample_sizes, weight_evolution['Cubic'], 'g-', label='Cubic')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Model Weight')\n",
    "plt.title('Evolution of Model Weights')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Bayes Factors:\n",
    "- **Direct evidence comparison** between models\n",
    "- **Automatic Occam's razor** - penalizes complexity\n",
    "- **Sensitive to priors** - especially for point hypotheses\n",
    "- **Interpretation guidelines** help decision making\n",
    "\n",
    "### Model Selection:\n",
    "- **WAIC/LOO** provide practical approximations\n",
    "- **Cross-validation** based approaches are robust\n",
    "- **Posterior predictive checks** assess model adequacy\n",
    "\n",
    "### Bayesian Model Averaging:\n",
    "- **Accounts for model uncertainty**\n",
    "- **Better calibrated predictions**\n",
    "- **Robust to model selection uncertainty**\n",
    "- **Computational overhead** but often worth it\n",
    "\n",
    "## Next: Topic 5 - Regression Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}