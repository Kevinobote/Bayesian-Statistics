{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 8: Applications of Bayesian Methods\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply Bayesian methods to real-world problems\n",
    "- Integrate multiple data sources and prior knowledge\n",
    "- Communicate Bayesian results effectively\n",
    "- Understand when and why to use Bayesian approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Case Study: Clinical Trial Analysis\n",
    "\n",
    "### Scenario:\n",
    "A pharmaceutical company is testing a new drug. They want to:\n",
    "- Incorporate prior knowledge from similar drugs\n",
    "- Make interim decisions during the trial\n",
    "- Quantify probability of success\n",
    "- Plan future studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical trial simulation\n",
    "def simulate_clinical_trial():\n",
    "    \"\"\"\n",
    "    Simulate a clinical trial with interim analyses\n",
    "    \"\"\"\n",
    "    # True treatment effects (unknown to investigators)\n",
    "    true_control_rate = 0.3\n",
    "    true_treatment_rate = 0.45  # 15% absolute improvement\n",
    "    \n",
    "    # Prior information from similar drugs\n",
    "    # Historical data suggests treatment effects between 0.05-0.25\n",
    "    prior_mean_effect = 0.15\n",
    "    prior_sd_effect = 0.05\n",
    "    \n",
    "    # Trial design\n",
    "    max_n_per_arm = 200\n",
    "    interim_analyses = [50, 100, 150, 200]  # Sample sizes for interim looks\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for n_per_arm in interim_analyses:\n",
    "        # Generate data up to current sample size\n",
    "        control_outcomes = np.random.binomial(1, true_control_rate, n_per_arm)\n",
    "        treatment_outcomes = np.random.binomial(1, true_treatment_rate, n_per_arm)\n",
    "        \n",
    "        # Bayesian analysis\n",
    "        with pm.Model() as trial_model:\n",
    "            # Priors for response rates\n",
    "            p_control = pm.Beta('p_control', 1, 1)  # Non-informative\n",
    "            \n",
    "            # Informative prior for treatment effect\n",
    "            treatment_effect = pm.Normal('treatment_effect', \n",
    "                                       prior_mean_effect, prior_sd_effect)\n",
    "            \n",
    "            # Treatment rate as function of control rate + effect\n",
    "            p_treatment = pm.Deterministic('p_treatment', \n",
    "                                         pm.math.clip(p_control + treatment_effect, 0, 1))\n",
    "            \n",
    "            # Likelihoods\n",
    "            control_obs = pm.Binomial('control_obs', n=n_per_arm, p=p_control, \n",
    "                                    observed=np.sum(control_outcomes))\n",
    "            treatment_obs = pm.Binomial('treatment_obs', n=n_per_arm, p=p_treatment, \n",
    "                                      observed=np.sum(treatment_outcomes))\n",
    "            \n",
    "            # Sample\n",
    "            trace = pm.sample(2000, return_inferencedata=True, random_seed=42)\n",
    "        \n",
    "        # Extract results\n",
    "        effect_samples = trace.posterior['treatment_effect'].values.flatten()\n",
    "        p_control_samples = trace.posterior['p_control'].values.flatten()\n",
    "        p_treatment_samples = trace.posterior['p_treatment'].values.flatten()\n",
    "        \n",
    "        # Key metrics\n",
    "        prob_positive_effect = np.mean(effect_samples > 0)\n",
    "        prob_clinically_meaningful = np.mean(effect_samples > 0.1)  # 10% threshold\n",
    "        prob_superiority = np.mean(p_treatment_samples > p_control_samples)\n",
    "        \n",
    "        effect_mean = np.mean(effect_samples)\n",
    "        effect_ci = np.percentile(effect_samples, [2.5, 97.5])\n",
    "        \n",
    "        results.append({\n",
    "            'n_per_arm': n_per_arm,\n",
    "            'control_successes': np.sum(control_outcomes),\n",
    "            'treatment_successes': np.sum(treatment_outcomes),\n",
    "            'observed_effect': np.sum(treatment_outcomes)/n_per_arm - np.sum(control_outcomes)/n_per_arm,\n",
    "            'posterior_effect_mean': effect_mean,\n",
    "            'effect_ci_lower': effect_ci[0],\n",
    "            'effect_ci_upper': effect_ci[1],\n",
    "            'prob_positive': prob_positive_effect,\n",
    "            'prob_meaningful': prob_clinically_meaningful,\n",
    "            'prob_superiority': prob_superiority\n",
    "        })\n",
    "    \n",
    "    return results, trace\n",
    "\n",
    "# Run trial simulation\n",
    "trial_results, final_trace = simulate_clinical_trial()\n",
    "\n",
    "# Display results\n",
    "print(\"Clinical Trial Interim Analyses:\")\n",
    "print(\"N/arm\\tControl\\tTreatment\\tObs Effect\\tPost Effect\\t95% CI\\t\\tP(+)\\tP(>10%)\\tP(Superior)\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for result in trial_results:\n",
    "    print(f\"{result['n_per_arm']}\\t{result['control_successes']}/{result['n_per_arm']}\\t\"\n",
    "          f\"{result['treatment_successes']}/{result['n_per_arm']}\\t\\t{result['observed_effect']:.3f}\\t\\t\"\n",
    "          f\"{result['posterior_effect_mean']:.3f}\\t\\t[{result['effect_ci_lower']:.3f}, {result['effect_ci_upper']:.3f}]\\t\"\n",
    "          f\"{result['prob_positive']:.3f}\\t{result['prob_meaningful']:.3f}\\t{result['prob_superiority']:.3f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Evolution of effect estimate\n",
    "n_values = [r['n_per_arm'] for r in trial_results]\n",
    "effect_means = [r['posterior_effect_mean'] for r in trial_results]\n",
    "effect_lowers = [r['effect_ci_lower'] for r in trial_results]\n",
    "effect_uppers = [r['effect_ci_upper'] for r in trial_results]\n",
    "observed_effects = [r['observed_effect'] for r in trial_results]\n",
    "\n",
    "axes[0,0].plot(n_values, effect_means, 'bo-', linewidth=2, label='Posterior Mean')\n",
    "axes[0,0].fill_between(n_values, effect_lowers, effect_uppers, alpha=0.3, label='95% CI')\n",
    "axes[0,0].plot(n_values, observed_effects, 'rs--', label='Observed Effect')\n",
    "axes[0,0].axhline(0.15, color='green', linestyle=':', label='True Effect')\n",
    "axes[0,0].axhline(0.1, color='red', linestyle='--', label='Clinically Meaningful')\n",
    "axes[0,0].set_xlabel('Sample Size per Arm')\n",
    "axes[0,0].set_ylabel('Treatment Effect')\n",
    "axes[0,0].set_title('Evolution of Treatment Effect Estimate')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Probability evolution\n",
    "prob_positive = [r['prob_positive'] for r in trial_results]\n",
    "prob_meaningful = [r['prob_meaningful'] for r in trial_results]\n",
    "prob_superiority = [r['prob_superiority'] for r in trial_results]\n",
    "\n",
    "axes[0,1].plot(n_values, prob_positive, 'b-', linewidth=2, label='P(Effect > 0)')\n",
    "axes[0,1].plot(n_values, prob_meaningful, 'r-', linewidth=2, label='P(Effect > 10%)')\n",
    "axes[0,1].plot(n_values, prob_superiority, 'g-', linewidth=2, label='P(Treatment Superior)')\n",
    "axes[0,1].axhline(0.95, color='black', linestyle='--', alpha=0.5, label='95% Threshold')\n",
    "axes[0,1].set_xlabel('Sample Size per Arm')\n",
    "axes[0,1].set_ylabel('Probability')\n",
    "axes[0,1].set_title('Evolution of Key Probabilities')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Final posterior distribution\n",
    "effect_samples = final_trace.posterior['treatment_effect'].values.flatten()\n",
    "axes[1,0].hist(effect_samples, bins=50, density=True, alpha=0.7, label='Posterior')\n",
    "axes[1,0].axvline(0.15, color='green', linestyle=':', linewidth=2, label='True Effect')\n",
    "axes[1,0].axvline(0.1, color='red', linestyle='--', linewidth=2, label='Clinical Threshold')\n",
    "axes[1,0].axvline(np.mean(effect_samples), color='blue', linestyle='-', linewidth=2, label='Posterior Mean')\n",
    "axes[1,0].set_xlabel('Treatment Effect')\n",
    "axes[1,0].set_ylabel('Density')\n",
    "axes[1,0].set_title('Final Posterior Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Decision analysis\n",
    "# Cost-benefit analysis\n",
    "cost_per_patient = 1000  # Cost of treatment\n",
    "benefit_per_success = 5000  # Benefit of successful treatment\n",
    "\n",
    "# Expected net benefit\n",
    "p_treatment_samples = final_trace.posterior['p_treatment'].values.flatten()\n",
    "p_control_samples = final_trace.posterior['p_control'].values.flatten()\n",
    "\n",
    "net_benefit_samples = (p_treatment_samples * benefit_per_success - cost_per_patient) - \\\n",
    "                     (p_control_samples * benefit_per_success)\n",
    "\n",
    "axes[1,1].hist(net_benefit_samples, bins=50, density=True, alpha=0.7)\n",
    "axes[1,1].axvline(0, color='red', linestyle='--', linewidth=2, label='Break-even')\n",
    "axes[1,1].axvline(np.mean(net_benefit_samples), color='blue', linestyle='-', \n",
    "                 linewidth=2, label='Expected Net Benefit')\n",
    "\n",
    "prob_profitable = np.mean(net_benefit_samples > 0)\n",
    "axes[1,1].set_xlabel('Net Benefit per Patient ($)')\n",
    "axes[1,1].set_ylabel('Density')\n",
    "axes[1,1].set_title(f'Economic Analysis\\nP(Profitable) = {prob_profitable:.3f}')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decision recommendations\n",
    "final_result = trial_results[-1]\n",
    "print(f\"\\nFinal Decision Analysis:\")\n",
    "print(f\"Probability of positive effect: {final_result['prob_positive']:.3f}\")\n",
    "print(f\"Probability of clinically meaningful effect (>10%): {final_result['prob_meaningful']:.3f}\")\n",
    "print(f\"Expected net benefit: ${np.mean(net_benefit_samples):.0f} per patient\")\n",
    "print(f\"Probability of profitability: {prob_profitable:.3f}\")\n",
    "\n",
    "if final_result['prob_meaningful'] > 0.8 and prob_profitable > 0.7:\n",
    "    decision = \"PROCEED to Phase III\"\n",
    "elif final_result['prob_positive'] > 0.9:\n",
    "    decision = \"CONSIDER proceeding with larger study\"\n",
    "else:\n",
    "    decision = \"DO NOT PROCEED - insufficient evidence\"\n",
    "\n",
    "print(f\"\\nRecommendation: {decision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Case Study: Marketing Mix Modeling\n",
    "\n",
    "### Scenario:\n",
    "A company wants to optimize their marketing spend across different channels:\n",
    "- TV, Digital, Print advertising\n",
    "- Account for saturation effects\n",
    "- Handle correlated media channels\n",
    "- Make budget allocation decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic marketing data\n",
    "np.random.seed(42)\n",
    "n_weeks = 104  # 2 years of weekly data\n",
    "\n",
    "# Media channels\n",
    "tv_spend = np.random.gamma(2, 50, n_weeks)  # TV spending\n",
    "digital_spend = np.random.gamma(1.5, 30, n_weeks)  # Digital spending\n",
    "print_spend = np.random.gamma(1, 20, n_weeks)  # Print spending\n",
    "\n",
    "# Add seasonality\n",
    "weeks = np.arange(n_weeks)\n",
    "seasonality = 10 * np.sin(2 * np.pi * weeks / 52) + 5 * np.sin(2 * np.pi * weeks / 52 * 2)\n",
    "\n",
    "# Adstock transformation (carryover effects)\n",
    "def adstock_transform(x, decay_rate):\n",
    "    \"\"\"Apply adstock transformation\"\"\"\n",
    "    adstocked = np.zeros_like(x)\n",
    "    adstocked[0] = x[0]\n",
    "    for i in range(1, len(x)):\n",
    "        adstocked[i] = x[i] + decay_rate * adstocked[i-1]\n",
    "    return adstocked\n",
    "\n",
    "# Saturation transformation\n",
    "def saturation_transform(x, alpha, gamma):\n",
    "    \"\"\"Apply saturation transformation\"\"\"\n",
    "    return alpha * (x ** gamma) / (x ** gamma + 1)\n",
    "\n",
    "# True parameters (unknown to modeler)\n",
    "true_params = {\n",
    "    'base': 100,\n",
    "    'tv_coef': 0.8,\n",
    "    'digital_coef': 1.2,\n",
    "    'print_coef': 0.4,\n",
    "    'tv_decay': 0.7,\n",
    "    'digital_decay': 0.3,\n",
    "    'print_decay': 0.5,\n",
    "    'tv_alpha': 50,\n",
    "    'tv_gamma': 0.5,\n",
    "    'digital_alpha': 30,\n",
    "    'digital_gamma': 0.7,\n",
    "    'print_alpha': 20,\n",
    "    'print_gamma': 0.6\n",
    "}\n",
    "\n",
    "# Generate sales with media effects\n",
    "tv_adstocked = adstock_transform(tv_spend, true_params['tv_decay'])\n",
    "digital_adstocked = adstock_transform(digital_spend, true_params['digital_decay'])\n",
    "print_adstocked = adstock_transform(print_spend, true_params['print_decay'])\n",
    "\n",
    "tv_saturated = saturation_transform(tv_adstocked, true_params['tv_alpha'], true_params['tv_gamma'])\n",
    "digital_saturated = saturation_transform(digital_adstocked, true_params['digital_alpha'], true_params['digital_gamma'])\n",
    "print_saturated = saturation_transform(print_adstocked, true_params['print_alpha'], true_params['print_gamma'])\n",
    "\n",
    "sales = (true_params['base'] + seasonality +\n",
    "         true_params['tv_coef'] * tv_saturated +\n",
    "         true_params['digital_coef'] * digital_saturated +\n",
    "         true_params['print_coef'] * print_saturated +\n",
    "         np.random.normal(0, 10, n_weeks))\n",
    "\n",
    "# Create DataFrame\n",
    "mmm_data = pd.DataFrame({\n",
    "    'week': weeks,\n",
    "    'sales': sales,\n",
    "    'tv_spend': tv_spend,\n",
    "    'digital_spend': digital_spend,\n",
    "    'print_spend': print_spend,\n",
    "    'seasonality': seasonality\n",
    "})\n",
    "\n",
    "print(\"Marketing Mix Model Data:\")\n",
    "print(mmm_data.describe())\n",
    "\n",
    "# Bayesian Marketing Mix Model\n",
    "with pm.Model() as mmm_model:\n",
    "    # Priors for base and seasonality\n",
    "    base = pm.Normal('base', 100, 20)\n",
    "    \n",
    "    # Priors for media coefficients\n",
    "    tv_coef = pm.HalfNormal('tv_coef', 2)\n",
    "    digital_coef = pm.HalfNormal('digital_coef', 2)\n",
    "    print_coef = pm.HalfNormal('print_coef', 2)\n",
    "    \n",
    "    # Priors for adstock decay rates\n",
    "    tv_decay = pm.Beta('tv_decay', 2, 2)\n",
    "    digital_decay = pm.Beta('digital_decay', 2, 2)\n",
    "    print_decay = pm.Beta('print_decay', 2, 2)\n",
    "    \n",
    "    # Priors for saturation parameters\n",
    "    tv_alpha = pm.HalfNormal('tv_alpha', 50)\n",
    "    tv_gamma = pm.Beta('tv_gamma', 2, 2)\n",
    "    digital_alpha = pm.HalfNormal('digital_alpha', 30)\n",
    "    digital_gamma = pm.Beta('digital_gamma', 2, 2)\n",
    "    print_alpha = pm.HalfNormal('print_alpha', 20)\n",
    "    print_gamma = pm.Beta('print_gamma', 2, 2)\n",
    "    \n",
    "    # Error term\n",
    "    sigma = pm.HalfNormal('sigma', 20)\n",
    "    \n",
    "    # Media transformations (simplified for PyMC)\n",
    "    # Note: In practice, you'd implement custom functions for adstock and saturation\n",
    "    \n",
    "    # Simplified model (linear approximation)\n",
    "    mu = (base + \n",
    "          tv_coef * tv_spend +\n",
    "          digital_coef * digital_spend +\n",
    "          print_coef * print_spend)\n",
    "    \n",
    "    # Likelihood\n",
    "    sales_obs = pm.Normal('sales_obs', mu=mu, sigma=sigma, observed=sales)\n",
    "    \n",
    "    # Sample\n",
    "    trace_mmm = pm.sample(1000, return_inferencedata=True, random_seed=42)\n",
    "\n",
    "print(\"\\nMarketing Mix Model Results:\")\n",
    "print(az.summary(trace_mmm, var_names=['base', 'tv_coef', 'digital_coef', 'print_coef']))\n",
    "\n",
    "# Media contribution analysis\n",
    "tv_coef_samples = trace_mmm.posterior['tv_coef'].values.flatten()\n",
    "digital_coef_samples = trace_mmm.posterior['digital_coef'].values.flatten()\n",
    "print_coef_samples = trace_mmm.posterior['print_coef'].values.flatten()\n",
    "\n",
    "# Calculate media contributions\n",
    "tv_contribution = np.mean(tv_coef_samples) * np.mean(tv_spend)\n",
    "digital_contribution = np.mean(digital_coef_samples) * np.mean(digital_spend)\n",
    "print_contribution = np.mean(print_coef_samples) * np.mean(print_spend)\n",
    "total_media_contribution = tv_contribution + digital_contribution + print_contribution\n",
    "\n",
    "# ROI calculation\n",
    "tv_roi = tv_contribution / np.mean(tv_spend)\n",
    "digital_roi = digital_contribution / np.mean(digital_spend)\n",
    "print_roi = print_contribution / np.mean(print_spend)\n",
    "\n",
    "print(f\"\\nMedia Contribution Analysis:\")\n",
    "print(f\"TV: {tv_contribution:.1f} sales units (ROI: {tv_roi:.2f})\")\n",
    "print(f\"Digital: {digital_contribution:.1f} sales units (ROI: {digital_roi:.2f})\")\n",
    "print(f\"Print: {print_contribution:.1f} sales units (ROI: {print_roi:.2f})\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Time series\n",
    "axes[0,0].plot(mmm_data['week'], mmm_data['sales'], 'b-', alpha=0.7, label='Actual Sales')\n",
    "# Fitted values (simplified)\n",
    "fitted = (np.mean(trace_mmm.posterior['base'].values) +\n",
    "          np.mean(tv_coef_samples) * tv_spend +\n",
    "          np.mean(digital_coef_samples) * digital_spend +\n",
    "          np.mean(print_coef_samples) * print_spend)\n",
    "axes[0,0].plot(mmm_data['week'], fitted, 'r--', alpha=0.7, label='Fitted')\n",
    "axes[0,0].set_xlabel('Week')\n",
    "axes[0,0].set_ylabel('Sales')\n",
    "axes[0,0].set_title('Sales vs Fitted Values')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Media spend correlation\n",
    "spend_corr = mmm_data[['tv_spend', 'digital_spend', 'print_spend']].corr()\n",
    "sns.heatmap(spend_corr, annot=True, cmap='coolwarm', center=0, ax=axes[0,1])\n",
    "axes[0,1].set_title('Media Spend Correlations')\n",
    "\n",
    "# ROI comparison\n",
    "channels = ['TV', 'Digital', 'Print']\n",
    "rois = [tv_roi, digital_roi, print_roi]\n",
    "colors = ['blue', 'green', 'orange']\n",
    "\n",
    "bars = axes[0,2].bar(channels, rois, color=colors, alpha=0.7)\n",
    "axes[0,2].set_ylabel('ROI (Sales per $ Spent)')\n",
    "axes[0,2].set_title('Return on Investment by Channel')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add ROI values on bars\n",
    "for bar, roi in zip(bars, rois):\n",
    "    height = bar.get_height()\n",
    "    axes[0,2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                  f'{roi:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Posterior distributions of coefficients\n",
    "axes[1,0].hist(tv_coef_samples, bins=30, alpha=0.7, label='TV', color='blue')\n",
    "axes[1,0].hist(digital_coef_samples, bins=30, alpha=0.7, label='Digital', color='green')\n",
    "axes[1,0].hist(print_coef_samples, bins=30, alpha=0.7, label='Print', color='orange')\n",
    "axes[1,0].set_xlabel('Coefficient Value')\n",
    "axes[1,0].set_ylabel('Density')\n",
    "axes[1,0].set_title('Posterior Distributions of Media Coefficients')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Budget optimization simulation\n",
    "total_budget = np.mean(tv_spend + digital_spend + print_spend)\n",
    "budget_scenarios = np.linspace(0.5, 2.0, 20)  # 50% to 200% of current budget\n",
    "\n",
    "# Optimal allocation (simplified - equal ROI principle)\n",
    "expected_sales = []\n",
    "for budget_mult in budget_scenarios:\n",
    "    new_budget = total_budget * budget_mult\n",
    "    \n",
    "    # Allocate proportionally to ROI\n",
    "    total_roi = tv_roi + digital_roi + print_roi\n",
    "    tv_allocation = new_budget * (tv_roi / total_roi)\n",
    "    digital_allocation = new_budget * (digital_roi / total_roi)\n",
    "    print_allocation = new_budget * (print_roi / total_roi)\n",
    "    \n",
    "    # Expected sales (linear approximation)\n",
    "    expected_sales_value = (np.mean(trace_mmm.posterior['base'].values) +\n",
    "                           np.mean(tv_coef_samples) * tv_allocation +\n",
    "                           np.mean(digital_coef_samples) * digital_allocation +\n",
    "                           np.mean(print_coef_samples) * print_allocation)\n",
    "    expected_sales.append(expected_sales_value)\n",
    "\n",
    "axes[1,1].plot(budget_scenarios, expected_sales, 'b-', linewidth=2)\n",
    "axes[1,1].axvline(1.0, color='red', linestyle='--', label='Current Budget')\n",
    "axes[1,1].set_xlabel('Budget Multiplier')\n",
    "axes[1,1].set_ylabel('Expected Sales')\n",
    "axes[1,1].set_title('Budget Optimization')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Contribution waterfall\n",
    "contributions = [tv_contribution, digital_contribution, print_contribution]\n",
    "base_sales = np.mean(trace_mmm.posterior['base'].values)\n",
    "\n",
    "x_pos = range(len(channels) + 2)\n",
    "values = [base_sales] + contributions + [base_sales + sum(contributions)]\n",
    "labels = ['Base'] + channels + ['Total']\n",
    "\n",
    "colors_waterfall = ['gray'] + colors + ['black']\n",
    "bars = axes[1,2].bar(x_pos, values, color=colors_waterfall, alpha=0.7)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, value) in enumerate(zip(bars, values)):\n",
    "    height = bar.get_height()\n",
    "    axes[1,2].text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                  f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "axes[1,2].set_xticks(x_pos)\n",
    "axes[1,2].set_xticklabels(labels)\n",
    "axes[1,2].set_ylabel('Sales Contribution')\n",
    "axes[1,2].set_title('Sales Contribution Waterfall')\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Strategic recommendations\n",
    "print(f\"\\nStrategic Recommendations:\")\n",
    "print(f\"1. Digital has highest ROI ({digital_roi:.2f}) - consider increasing allocation\")\n",
    "print(f\"2. Print has lowest ROI ({print_roi:.2f}) - consider reducing allocation\")\n",
    "print(f\"3. Current total media contribution: {total_media_contribution:.0f} sales units\")\n",
    "print(f\"4. Media accounts for {total_media_contribution/np.mean(sales)*100:.1f}% of total sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Best Practices for Bayesian Applications\n",
    "\n",
    "### When to Use Bayesian Methods:\n",
    "1. **Prior information available**: Expert knowledge, historical data\n",
    "2. **Small sample sizes**: Bayesian methods handle uncertainty better\n",
    "3. **Sequential decision making**: Clinical trials, A/B testing\n",
    "4. **Complex hierarchical structure**: Multi-level data\n",
    "5. **Missing data**: Natural imputation framework\n",
    "6. **Uncertainty quantification**: Need full posterior distributions\n",
    "\n",
    "### Communication Guidelines:\n",
    "1. **Focus on probabilities**: \"95% probability that...\"\n",
    "2. **Use credible intervals**: More intuitive than confidence intervals\n",
    "3. **Visualize uncertainty**: Show full distributions when possible\n",
    "4. **Explain prior assumptions**: Be transparent about assumptions\n",
    "5. **Sensitivity analysis**: Show robustness to prior choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Communicating Bayesian Results\n",
    "def create_bayesian_report(trace, parameter_name, true_value=None, \n",
    "                          threshold=None, context=\"parameter\"):\n",
    "    \"\"\"\n",
    "    Create a comprehensive report for a Bayesian parameter\n",
    "    \"\"\"\n",
    "    samples = trace.posterior[parameter_name].values.flatten()\n",
    "    \n",
    "    # Summary statistics\n",
    "    mean_val = np.mean(samples)\n",
    "    median_val = np.median(samples)\n",
    "    std_val = np.std(samples)\n",
    "    ci_95 = np.percentile(samples, [2.5, 97.5])\n",
    "    ci_90 = np.percentile(samples, [5, 95])\n",
    "    ci_50 = np.percentile(samples, [25, 75])\n",
    "    \n",
    "    print(f\"\\n=== Bayesian Analysis Report: {parameter_name} ===\")\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"\\nPosterior Summary:\")\n",
    "    print(f\"  Mean: {mean_val:.4f}\")\n",
    "    print(f\"  Median: {median_val:.4f}\")\n",
    "    print(f\"  Standard Deviation: {std_val:.4f}\")\n",
    "    print(f\"\\nCredible Intervals:\")\n",
    "    print(f\"  50%: [{ci_50[0]:.4f}, {ci_50[1]:.4f}]\")\n",
    "    print(f\"  90%: [{ci_90[0]:.4f}, {ci_90[1]:.4f}]\")\n",
    "    print(f\"  95%: [{ci_95[0]:.4f}, {ci_95[1]:.4f}]\")\n",
    "    \n",
    "    # Probability statements\n",
    "    if threshold is not None:\n",
    "        prob_above = np.mean(samples > threshold)\n",
    "        prob_below = np.mean(samples < threshold)\n",
    "        print(f\"\\nProbability Statements:\")\n",
    "        print(f\"  P({parameter_name} > {threshold}) = {prob_above:.3f}\")\n",
    "        print(f\"  P({parameter_name} < {threshold}) = {prob_below:.3f}\")\n",
    "    \n",
    "    # Comparison with true value if available\n",
    "    if true_value is not None:\n",
    "        prob_covers = (ci_95[0] <= true_value <= ci_95[1])\n",
    "        distance_from_mean = abs(mean_val - true_value)\n",
    "        print(f\"\\nValidation (True value = {true_value}):\")\n",
    "        print(f\"  95% CI covers true value: {prob_covers}\")\n",
    "        print(f\"  Distance from posterior mean: {distance_from_mean:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Posterior distribution\n",
    "    axes[0].hist(samples, bins=50, density=True, alpha=0.7, color='skyblue')\n",
    "    axes[0].axvline(mean_val, color='red', linestyle='-', linewidth=2, label=f'Mean = {mean_val:.3f}')\n",
    "    axes[0].axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'Median = {median_val:.3f}')\n",
    "    \n",
    "    # Credible intervals\n",
    "    axes[0].axvspan(ci_95[0], ci_95[1], alpha=0.2, color='red', label='95% CI')\n",
    "    axes[0].axvspan(ci_50[0], ci_50[1], alpha=0.3, color='orange', label='50% CI')\n",
    "    \n",
    "    if true_value is not None:\n",
    "        axes[0].axvline(true_value, color='black', linestyle=':', linewidth=2, label=f'True = {true_value}')\n",
    "    \n",
    "    if threshold is not None:\n",
    "        axes[0].axvline(threshold, color='purple', linestyle='-.', linewidth=2, label=f'Threshold = {threshold}')\n",
    "    \n",
    "    axes[0].set_xlabel(parameter_name)\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].set_title('Posterior Distribution')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Cumulative distribution\n",
    "    sorted_samples = np.sort(samples)\n",
    "    cumulative_prob = np.arange(1, len(sorted_samples) + 1) / len(sorted_samples)\n",
    "    \n",
    "    axes[1].plot(sorted_samples, cumulative_prob, 'b-', linewidth=2)\n",
    "    axes[1].axhline(0.5, color='green', linestyle='--', alpha=0.7, label='Median')\n",
    "    axes[1].axhline(0.025, color='red', linestyle=':', alpha=0.7, label='2.5%')\n",
    "    axes[1].axhline(0.975, color='red', linestyle=':', alpha=0.7, label='97.5%')\n",
    "    \n",
    "    if threshold is not None:\n",
    "        prob_at_threshold = np.mean(samples <= threshold)\n",
    "        axes[1].axvline(threshold, color='purple', linestyle='-.', linewidth=2)\n",
    "        axes[1].axhline(prob_at_threshold, color='purple', linestyle='-.', alpha=0.7)\n",
    "        axes[1].text(threshold, prob_at_threshold + 0.05, \n",
    "                    f'P â‰¤ {threshold} = {prob_at_threshold:.3f}', \n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    axes[1].set_xlabel(parameter_name)\n",
    "    axes[1].set_ylabel('Cumulative Probability')\n",
    "    axes[1].set_title('Cumulative Distribution Function')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'mean': mean_val,\n",
    "        'median': median_val,\n",
    "        'std': std_val,\n",
    "        'ci_95': ci_95,\n",
    "        'ci_90': ci_90,\n",
    "        'ci_50': ci_50\n",
    "    }\n",
    "\n",
    "# Example usage with clinical trial data\n",
    "treatment_effect_report = create_bayesian_report(\n",
    "    final_trace, \n",
    "    'treatment_effect', \n",
    "    true_value=0.15, \n",
    "    threshold=0.1,\n",
    "    context=\"Treatment effect in clinical trial (absolute difference in response rates)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Summary\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. **Foundations**: Bayes' theorem, prior/posterior concepts\n",
    "2. **Prior Selection**: Conjugate, non-informative, elicitation\n",
    "3. **Decision Theory**: Loss functions, point estimation, intervals\n",
    "4. **Model Comparison**: Bayes factors, model averaging\n",
    "5. **Regression**: Linear, logistic, Poisson models\n",
    "6. **Hierarchical Models**: Partial pooling, missing data\n",
    "7. **MCMC**: Sampling algorithms, diagnostics\n",
    "8. **Applications**: Real-world case studies\n",
    "\n",
    "### Key Advantages of Bayesian Approach:\n",
    "- **Intuitive probability interpretation**\n",
    "- **Incorporates prior knowledge**\n",
    "- **Quantifies uncertainty naturally**\n",
    "- **Handles complex models flexibly**\n",
    "- **Provides decision-theoretic framework**\n",
    "\n",
    "### Next Steps:\n",
    "1. **Practice with real data**: Apply methods to your domain\n",
    "2. **Learn advanced topics**: Gaussian processes, variational inference\n",
    "3. **Explore specialized packages**: Stan, JAGS, TensorFlow Probability\n",
    "4. **Study computational methods**: Variational Bayes, approximate methods\n",
    "5. **Read current literature**: Bayesian workflow, model checking\n",
    "\n",
    "### Resources for Continued Learning:\n",
    "- **Books**: Gelman et al. \"Bayesian Data Analysis\", McElreath \"Statistical Rethinking\"\n",
    "- **Software**: PyMC, Stan, ArviZ\n",
    "- **Communities**: PyMC Discourse, Stan Forums\n",
    "- **Courses**: Advanced Bayesian methods, computational statistics\n",
    "\n",
    "**Remember**: Bayesian statistics is as much about thinking probabilistically as it is about computation. The key is to start simple, build intuition, and gradually tackle more complex problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}