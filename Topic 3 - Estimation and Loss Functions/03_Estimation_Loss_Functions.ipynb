{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 3: Estimation and Loss Functions\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand Bayesian point estimation\n",
    "- Master different loss functions and their optimal estimators\n",
    "- Compare Bayesian and frequentist interval estimation\n",
    "- Apply decision theory to parameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayesian Point Estimation\n",
    "\n",
    "### Common Loss Functions and Optimal Estimators:\n",
    "\n",
    "| Loss Function | Formula | Optimal Estimator |\n",
    "|---------------|---------|------------------|\n",
    "| Squared Error | $L(\\theta, \\hat{\\theta}) = (\\theta - \\hat{\\theta})^2$ | Posterior Mean |\n",
    "| Absolute Error | $L(\\theta, \\hat{\\theta}) = |\\theta - \\hat{\\theta}|$ | Posterior Median |\n",
    "| 0-1 Loss | $L(\\theta, \\hat{\\theta}) = \\mathbb{I}(\\theta \\neq \\hat{\\theta})$ | Posterior Mode |\n",
    "\n",
    "### Expected Loss (Risk):\n",
    "$$R(\\hat{\\theta}) = E[L(\\theta, \\hat{\\theta})] = \\int L(\\theta, \\hat{\\theta}) p(\\theta|D) d\\theta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different point estimators\n",
    "# Data: Beta-Binomial example\n",
    "alpha_prior, beta_prior = 2, 3\n",
    "successes, trials = 8, 15\n",
    "\n",
    "# Posterior\n",
    "alpha_post = alpha_prior + successes\n",
    "beta_post = beta_prior + trials - successes\n",
    "posterior = stats.beta(alpha_post, beta_post)\n",
    "\n",
    "# Point estimates\n",
    "posterior_mean = posterior.mean()\n",
    "posterior_median = posterior.median()\n",
    "posterior_mode = (alpha_post - 1) / (alpha_post + beta_post - 2)  # For Beta distribution\n",
    "\n",
    "print(f\"Posterior: Beta({alpha_post}, {beta_post})\")\n",
    "print(f\"Posterior Mean (squared loss): {posterior_mean:.4f}\")\n",
    "print(f\"Posterior Median (absolute loss): {posterior_median:.4f}\")\n",
    "print(f\"Posterior Mode (0-1 loss): {posterior_mode:.4f}\")\n",
    "print(f\"MLE: {successes/trials:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "x = np.linspace(0, 1, 1000)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, posterior.pdf(x), 'b-', linewidth=2, label='Posterior')\n",
    "plt.axvline(posterior_mean, color='red', linestyle='-', label=f'Mean = {posterior_mean:.3f}')\n",
    "plt.axvline(posterior_median, color='green', linestyle='--', label=f'Median = {posterior_median:.3f}')\n",
    "plt.axvline(posterior_mode, color='orange', linestyle=':', label=f'Mode = {posterior_mode:.3f}')\n",
    "plt.axvline(successes/trials, color='black', linestyle='-.', label=f'MLE = {successes/trials:.3f}')\n",
    "plt.xlabel('θ')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Point Estimators')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Risk comparison\n",
    "theta_true = 0.6  # Assume true value\n",
    "estimators = {\n",
    "    'Mean': posterior_mean,\n",
    "    'Median': posterior_median,\n",
    "    'Mode': posterior_mode,\n",
    "    'MLE': successes/trials\n",
    "}\n",
    "\n",
    "squared_errors = {name: (est - theta_true)**2 for name, est in estimators.items()}\n",
    "absolute_errors = {name: abs(est - theta_true) for name, est in estimators.items()}\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "names = list(estimators.keys())\n",
    "sq_errs = [squared_errors[name] for name in names]\n",
    "abs_errs = [absolute_errors[name] for name in names]\n",
    "\n",
    "x_pos = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x_pos - width/2, sq_errs, width, label='Squared Error', alpha=0.7)\n",
    "plt.bar(x_pos + width/2, abs_errs, width, label='Absolute Error', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Estimator')\n",
    "plt.ylabel('Error')\n",
    "plt.title(f'Estimation Errors (True θ = {theta_true})')\n",
    "plt.xticks(x_pos, names)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Credible Intervals vs Confidence Intervals\n",
    "\n",
    "### Credible Interval (Bayesian):\n",
    "- **Interpretation**: \"There is a 95% probability that θ lies in this interval\"\n",
    "- **Construction**: Find interval [a,b] such that $P(a ≤ θ ≤ b|D) = 0.95$\n",
    "\n",
    "### Confidence Interval (Frequentist):\n",
    "- **Interpretation**: \"If we repeat this procedure many times, 95% of intervals will contain the true θ\"\n",
    "- **Construction**: Based on sampling distribution of estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare credible and confidence intervals\n",
    "# Simulation study\n",
    "\n",
    "def simulate_intervals(true_p, n_trials, n_simulations=1000):\n",
    "    \"\"\"\n",
    "    Simulate Bayesian credible intervals and frequentist confidence intervals\n",
    "    \"\"\"\n",
    "    # Storage\n",
    "    bayesian_covers = []\n",
    "    frequentist_covers = []\n",
    "    bayesian_widths = []\n",
    "    frequentist_widths = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # Generate data\n",
    "        successes = np.random.binomial(n_trials, true_p)\n",
    "        \n",
    "        # Bayesian credible interval (uniform prior)\n",
    "        posterior = stats.beta(1 + successes, 1 + n_trials - successes)\n",
    "        bay_ci = posterior.ppf([0.025, 0.975])\n",
    "        \n",
    "        # Frequentist confidence interval (Wald)\n",
    "        p_hat = successes / n_trials\n",
    "        se = np.sqrt(p_hat * (1 - p_hat) / n_trials)\n",
    "        freq_ci = [p_hat - 1.96 * se, p_hat + 1.96 * se]\n",
    "        freq_ci = [max(0, freq_ci[0]), min(1, freq_ci[1])]  # Truncate to [0,1]\n",
    "        \n",
    "        # Check coverage\n",
    "        bayesian_covers.append(bay_ci[0] <= true_p <= bay_ci[1])\n",
    "        frequentist_covers.append(freq_ci[0] <= true_p <= freq_ci[1])\n",
    "        \n",
    "        # Calculate widths\n",
    "        bayesian_widths.append(bay_ci[1] - bay_ci[0])\n",
    "        frequentist_widths.append(freq_ci[1] - freq_ci[0])\n",
    "    \n",
    "    return {\n",
    "        'bayesian_coverage': np.mean(bayesian_covers),\n",
    "        'frequentist_coverage': np.mean(frequentist_covers),\n",
    "        'bayesian_width': np.mean(bayesian_widths),\n",
    "        'frequentist_width': np.mean(frequentist_widths)\n",
    "    }\n",
    "\n",
    "# Run simulation\n",
    "true_p = 0.3\n",
    "n_trials = 50\n",
    "results = simulate_intervals(true_p, n_trials)\n",
    "\n",
    "print(f\"Simulation Results (true p = {true_p}, n = {n_trials}):\")\n",
    "print(f\"Bayesian 95% credible interval coverage: {results['bayesian_coverage']:.3f}\")\n",
    "print(f\"Frequentist 95% confidence interval coverage: {results['frequentist_coverage']:.3f}\")\n",
    "print(f\"Average Bayesian interval width: {results['bayesian_width']:.3f}\")\n",
    "print(f\"Average Frequentist interval width: {results['frequentist_width']:.3f}\")\n",
    "\n",
    "# Visualize single example\n",
    "np.random.seed(42)\n",
    "successes = np.random.binomial(n_trials, true_p)\n",
    "p_hat = successes / n_trials\n",
    "\n",
    "# Bayesian\n",
    "posterior = stats.beta(1 + successes, 1 + n_trials - successes)\n",
    "bay_ci = posterior.ppf([0.025, 0.975])\n",
    "\n",
    "# Frequentist\n",
    "se = np.sqrt(p_hat * (1 - p_hat) / n_trials)\n",
    "freq_ci = [p_hat - 1.96 * se, p_hat + 1.96 * se]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Posterior distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "x = np.linspace(0, 0.8, 1000)\n",
    "plt.plot(x, posterior.pdf(x), 'b-', linewidth=2, label='Posterior')\n",
    "plt.axvspan(bay_ci[0], bay_ci[1], alpha=0.3, color='blue', label='95% Credible Interval')\n",
    "plt.axvline(true_p, color='red', linestyle='--', label=f'True p = {true_p}')\n",
    "plt.axvline(p_hat, color='green', linestyle=':', label=f'Observed p̂ = {p_hat:.2f}')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Bayesian Credible Interval')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.errorbar([1], [p_hat], yerr=[[p_hat - bay_ci[0]], [bay_ci[1] - p_hat]], \n",
    "            fmt='bo', capsize=5, capthick=2, label='Bayesian 95% CI')\n",
    "plt.errorbar([2], [p_hat], yerr=[[p_hat - freq_ci[0]], [freq_ci[1] - p_hat]], \n",
    "            fmt='ro', capsize=5, capthick=2, label='Frequentist 95% CI')\n",
    "plt.axhline(true_p, color='black', linestyle='--', label=f'True p = {true_p}')\n",
    "plt.xlim(0.5, 2.5)\n",
    "plt.xticks([1, 2], ['Bayesian', 'Frequentist'])\n",
    "plt.ylabel('p')\n",
    "plt.title('Interval Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSingle Example (observed {successes}/{n_trials} successes):\")\n",
    "print(f\"Bayesian 95% CI: [{bay_ci[0]:.3f}, {bay_ci[1]:.3f}] (width: {bay_ci[1]-bay_ci[0]:.3f})\")\n",
    "print(f\"Frequentist 95% CI: [{freq_ci[0]:.3f}, {freq_ci[1]:.3f}] (width: {freq_ci[1]-freq_ci[0]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Theory Application\n",
    "\n",
    "### Example: Quality Control Decision\n",
    "- **Action A₁**: Accept batch (cost = 0 if good, cost = 100 if bad)\n",
    "- **Action A₂**: Reject batch (cost = 10 always)\n",
    "\n",
    "**Decision Rule**: Choose action that minimizes expected loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality control decision problem\n",
    "# Defect rate θ, observe x defects in n items\n",
    "\n",
    "def quality_control_decision(x_defects, n_items, alpha_prior=1, beta_prior=1, \n",
    "                           cost_accept_good=0, cost_accept_bad=100, cost_reject=10,\n",
    "                           threshold_bad=0.05):\n",
    "    \"\"\"\n",
    "    Make quality control decision using Bayesian decision theory\n",
    "    \"\"\"\n",
    "    # Posterior\n",
    "    alpha_post = alpha_prior + x_defects\n",
    "    beta_post = beta_prior + n_items - x_defects\n",
    "    posterior = stats.beta(alpha_post, beta_post)\n",
    "    \n",
    "    # Probability batch is \"bad\" (defect rate > threshold)\n",
    "    prob_bad = 1 - posterior.cdf(threshold_bad)\n",
    "    prob_good = 1 - prob_bad\n",
    "    \n",
    "    # Expected costs\n",
    "    expected_cost_accept = (prob_good * cost_accept_good + \n",
    "                           prob_bad * cost_accept_bad)\n",
    "    expected_cost_reject = cost_reject\n",
    "    \n",
    "    # Decision\n",
    "    if expected_cost_accept < expected_cost_reject:\n",
    "        decision = \"Accept\"\n",
    "        min_cost = expected_cost_accept\n",
    "    else:\n",
    "        decision = \"Reject\"\n",
    "        min_cost = expected_cost_reject\n",
    "    \n",
    "    return {\n",
    "        'decision': decision,\n",
    "        'prob_bad': prob_bad,\n",
    "        'expected_cost_accept': expected_cost_accept,\n",
    "        'expected_cost_reject': expected_cost_reject,\n",
    "        'min_expected_cost': min_cost,\n",
    "        'posterior_mean': posterior.mean()\n",
    "    }\n",
    "\n",
    "# Example scenarios\n",
    "scenarios = [\n",
    "    (2, 100, \"Low defects\"),\n",
    "    (5, 100, \"Medium defects\"),\n",
    "    (8, 100, \"High defects\"),\n",
    "    (12, 100, \"Very high defects\")\n",
    "]\n",
    "\n",
    "print(\"Quality Control Decision Analysis:\")\n",
    "print(\"Costs: Accept good batch = 0, Accept bad batch = 100, Reject = 10\")\n",
    "print(\"Bad batch threshold: defect rate > 5%\")\n",
    "print(\"\\nScenario\\t\\tDefects\\tP(Bad)\\tDecision\\tExpected Cost\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "results = []\n",
    "for x_defects, n_items, description in scenarios:\n",
    "    result = quality_control_decision(x_defects, n_items)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"{description:<15}\\t{x_defects}/{n_items}\\t{result['prob_bad']:.3f}\\t{result['decision']}\\t\\t{result['min_expected_cost']:.1f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ((x_defects, n_items, description), result) in enumerate(zip(scenarios, results)):\n",
    "    # Posterior distribution\n",
    "    alpha_post = 1 + x_defects\n",
    "    beta_post = 1 + n_items - x_defects\n",
    "    posterior = stats.beta(alpha_post, beta_post)\n",
    "    \n",
    "    x = np.linspace(0, 0.2, 1000)\n",
    "    axes[i].plot(x, posterior.pdf(x), 'b-', linewidth=2, label='Posterior')\n",
    "    axes[i].axvline(0.05, color='red', linestyle='--', label='Threshold (5%)')\n",
    "    \n",
    "    # Shade \"bad\" region\n",
    "    x_bad = x[x >= 0.05]\n",
    "    y_bad = posterior.pdf(x_bad)\n",
    "    axes[i].fill_between(x_bad, y_bad, alpha=0.3, color='red', \n",
    "                        label=f'P(Bad) = {result[\"prob_bad\"]:.3f}')\n",
    "    \n",
    "    axes[i].set_title(f'{description}\\nDecision: {result[\"decision\"]} (Cost: {result[\"min_expected_cost\"]:.1f})')\n",
    "    axes[i].set_xlabel('Defect Rate')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decision boundary analysis\n",
    "x_range = range(0, 15)\n",
    "decisions = []\n",
    "costs = []\n",
    "\n",
    "for x in x_range:\n",
    "    result = quality_control_decision(x, 100)\n",
    "    decisions.append(1 if result['decision'] == 'Accept' else 0)\n",
    "    costs.append(result['min_expected_cost'])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['red' if d == 0 else 'green' for d in decisions]\n",
    "plt.bar(x_range, [1]*len(x_range), color=colors, alpha=0.7)\n",
    "plt.xlabel('Number of Defects (out of 100)')\n",
    "plt.ylabel('Decision')\n",
    "plt.title('Decision Boundary')\n",
    "plt.yticks([0, 1], ['Reject', 'Accept'])\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_range, costs, 'bo-', linewidth=2, markersize=6)\n",
    "plt.xlabel('Number of Defects (out of 100)')\n",
    "plt.ylabel('Minimum Expected Cost')\n",
    "plt.title('Expected Cost vs Defects')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Point Estimation:\n",
    "- **Choice of loss function** determines optimal estimator\n",
    "- **Squared loss** → posterior mean (most common)\n",
    "- **Absolute loss** → posterior median (robust)\n",
    "- **0-1 loss** → posterior mode (MAP estimate)\n",
    "\n",
    "### Interval Estimation:\n",
    "- **Credible intervals**: Direct probability statements about parameters\n",
    "- **Confidence intervals**: Frequency properties of the procedure\n",
    "- **Bayesian interpretation** is more intuitive for decision making\n",
    "\n",
    "### Decision Theory:\n",
    "- **Formal framework** for incorporating costs and utilities\n",
    "- **Expected loss minimization** provides optimal decisions\n",
    "- **Sensitivity analysis** important for cost assumptions\n",
    "\n",
    "## Next: Topic 4 - Hypothesis Testing and Model Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}